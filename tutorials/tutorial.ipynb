{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "swmr_tools can be installed using conda (from the conda-forge channel) or pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSource\n",
    "\n",
    "The DataSource class is designed to facilitate live data processing of\n",
    "datasets contained within an hdf5 file. It achieves this through following\n",
    "a set of *key* datasets and reading the corresponding data once all the keys are non-zero:\n",
    "\n",
    "This tutorial assumes a basic level of skill using the h5py library.\n",
    "Specifically, you should be comfortable with using h5py to:\n",
    "\n",
    "* Open and create hdf5_files\n",
    "* Navigate files using python dictionary methods\n",
    "* Create groups and datasets\n",
    "\n",
    "If you are unfamiliar with how to do any of this we recommend reading the\n",
    "h5py quick start guide: https://docs.h5py.org/en/stable/quick.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Iteration through a 4D dataset as images, writing image sum to a new file\n",
    "We will create a dataset of non-zero integers, respresenting a complete scan, with all sets of\n",
    "frames flushed to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from swmr_tools import DataSource,utils\n",
    "import numpy as np\n",
    "\n",
    "#create some constants\n",
    "\n",
    "test_file = \"test_file.h5\"\n",
    "result_file = \"sum.h5\"\n",
    "data_path = \"/data/data_1\"\n",
    "key_path = \"/keys/key_1\"\n",
    "\n",
    "#create a sequential array of the numbers 1-6 and reshape them into an array\n",
    "# of shape (2,3,1,1)\n",
    "complete_key_array = np.arange(6).reshape(2,3,1,1) + 1\n",
    "#make grid of [5,10] images\n",
    "complete_data_dataset = np.random.randint(low = 0, high = 1000, size = (2,3,5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_key_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty hdf5 file, create a group called \"keys\" and create\n",
    "a dataset in that group called \"key_1\" where we will add our array of non-zero\n",
    "keys, and a group called data, with dataset called data_1, which is the data we want to process (a 2x3 grid of \\[5,10\\] shaped images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(test_file, \"w\", libver = \"latest\") as f:\n",
    "    f.create_group(\"keys\")\n",
    "    f[\"keys\"].create_dataset(\"key_1\", data = complete_key_array)\n",
    "    f.create_group(\"data\")\n",
    "    f[\"data\"].create_dataset(\"data_1\", data = complete_data_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Next, we shall create an instance of the DataSource class and demonstrate a\n",
    "simple example of its use. At a minimum we must pass the h5py.File object\n",
    "we wish to read from, a list containing the paths to the hdf5 groups\n",
    "containing our keys and a list containing the datasets we want to process.\n",
    "\n",
    "Shown below is an example of using an instance of DataSource within a for loop,\n",
    "as you would with any standard iterable object. For this basic example of a\n",
    "dataset containing only non-zero values, the loop runs 6 times and stops as\n",
    "expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first check file and datasets are readable\n",
    "utils.check_file_readable(test_file,[key_path,data_path])\n",
    "\n",
    "# using an instance of Datasource in a for loop\n",
    "with h5py.File(test_file, \"r\", libver = \"latest\", swmr = True) as f, h5py.File(result_file, \"w\",libver = \"latest\") as oh:\n",
    "    keys = [f['/keys/keys_1']]\n",
    "    datasets = {'/data/data_1' : f['/data/data_1'],\n",
    "    '/data/data_2' : f['/data/data_2']}\n",
    "    ds = DataSource(keys,datasets, timeout = 1)\n",
    "    sum_dataset = None\n",
    "    for dm in ds:\n",
    "        s = dm[data_path].sum()\n",
    "        \n",
    "        if sum_dataset is None:\n",
    "            sum_dataset = ds.create_dataset(s,oh,\"result\")\n",
    "        else:\n",
    "            ds.append_data(s,dm.slice_metadata,sum_dataset)\n",
    "\n",
    "        sum_dataset.flush()\n",
    "        print(\"Current result :\" + str(sum_dataset[...]))\n",
    "    \n",
    "    print(\"Result dataset has shape: \" + str(oh[\"/result\"].shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which shows the DataSource iterating over the 6 \\[1,1,5,10\\] datasets, which slice of the 2x3 block each image is taken from, and writing the sum of the image into a new file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
